{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW6x35U5USVQ"
      },
      "source": [
        "# Шумоподавляющий автокодировщик\n",
        "\n",
        "Denoising autoencoder (DAE)\n",
        "\n",
        "Задание: создать модель для подавления шумов в медицинских изображениях.\n",
        "\n",
        "В этой работе мы повторим идею из статьи \"Medical image denoising using convolutional denoising autoencoders\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bbyt82J-N1m"
      },
      "outputs": [],
      "source": [
        "# код для варианта\n",
        "\n",
        "name = \"\" # Впишите ваше ФИО\n",
        "\n",
        "def calculate_variant(name):\n",
        "    return sum(ord(char) for char in name) % 3 + 1\n",
        "\n",
        "print(f\"Ваш вариант - №{calculate_variant(name)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65zOCnPV-Usu"
      },
      "source": [
        "## Варианты\n",
        "\n",
        "1. OrganSMNIST\n",
        "1. ChestMNIST\n",
        "1. PneumoniaMNIST\n",
        "\n",
        "## Порядок выполнения\n",
        "\n",
        "1. Загрузить датасет по варианту;\n",
        "1. Провести предварительную обработку данных;\n",
        "1. Используя фреймворк PyTorch создать модель;\n",
        "1. Обучить модель;\n",
        "1. Попробовать подобрать гиперпараметры;\n",
        "1. Оценить результаты лучшей модели на тестовой выборке.\n",
        "\n",
        "## Источники\n",
        "\n",
        "1. [Medical image denoising using convolutional denoising autoencoders](https://arxiv.org/pdf/1608.04667.pdf)\n",
        "1. [Автоэнкодеры: типы архитектур и применение](https://neurohive.io/ru/osnovy-data-science/avtojenkoder-tipy-arhitektur-i-primenenie/)\n",
        "1. [Автокодировщик](https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA)\n",
        "\n",
        "## Статьи для примера\n",
        "\n",
        "1. [LLNet: A Deep Autoencoder approach to Natural Low-light Image Enhancement](https://arxiv.org/pdf/1511.03995.pdf)\n",
        "1. [Deep Learning on Image Denoising: An Overview](https://arxiv.org/pdf/1912.13171.pdf)\n",
        "1. [Boltzmann Machines and Denoising Autoencoders for Image Denoising](https://arxiv.org/pdf/1301.3468.pdf)\n",
        "1. [Denoising Vanilla Autoencoder for RGB and GS Images with Gaussian Noise](https://app.dimensions.ai/details/publication/pub.1165117438)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWtUeaA--vJa"
      },
      "source": [
        "## Импортирование модулей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr9royZLlLXu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb-ePLUw--6V"
      },
      "source": [
        "В этой работе можете попробовать задействовать GPU для ускорения вычислений. [How To Use GPU with PyTorch](https://wandb.ai/wandb/common-ml-errors/reports/How-To-Use-GPU-with-PyTorch---VmlldzozMzAxMDk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayOmJFjL-8uD"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print('Работаем на GPU')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('Работаем на CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiGouVwmGc5D"
      },
      "source": [
        "Изначально тензоры создаются на CPU, и с помощью метода `.to(device)` на тензорах и моделях вы можете переносить их с устройства на устройство. Если в результате вычислений создаются новые тензоры, то они уже создаются на устройствах, на которых производились эти вычисления."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT4QchL2HMgu"
      },
      "source": [
        "## Загрузка данных\n",
        "\n",
        "Ссылка на подборку датасетов - https://medmnist.com/. По этой ссылке вы найдете описание самих датасетов, а также инструкцию по установке библиотеки и созданию объекта DataClass и далее DataLoader.\n",
        "\n",
        "[Официальный пример](https://github.com/MedMNIST/MedMNIST/blob/main/examples/getting_started.ipynb) как пользоваться датасетом и как загрузить его данные от самих разработчиков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIH-iTg4HM2f"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Ваш код для DataSet и DataLoader\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnHvLDY_Soml"
      },
      "source": [
        "**Какие преобразования вы применили при создании DataSet и почему?**\n",
        "\n",
        "Ваш ответ:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anYEXiGqLom6"
      },
      "source": [
        "## Создание модели\n",
        "\n",
        "Автокодировщик (автоэнкодер) состоит из двух частей и вывод первой части является входом второй части. Строение модели вы можете посмотреть в статье в описании и воспроизвести ее. Создание слоев свертки вам знакомо с предыдущей работы, а для декодера вам потребуется двумерная транспонированная свертка (ConvTranspose2d)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nVkR8lnL8AP"
      },
      "outputs": [],
      "source": [
        "# кодировщик\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        #\n",
        "        # ваш код\n",
        "        #\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return output  # здесь на выходе может быть произвольный тензор\n",
        "\n",
        "\n",
        "#  декодер\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        #\n",
        "        # ваш код\n",
        "        #\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Помните, что здесь на входе должен приниматься тензор размерностью как у кодировщика на выходе\n",
        "    #\n",
        "    # ваш код\n",
        "    #\n",
        "    return output  # На выходе должен быть тензор размерностью как исходное изображение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1D2jcsnSycO"
      },
      "source": [
        "**В чем разница между сверткой и транспонированной сверткой?**\n",
        "\n",
        "Ваш ответ:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQzghVCAN972"
      },
      "source": [
        "Далее кодировщик и декодировщик мы объединяем в автокодировщик."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGB5oYVUN9OH"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    # self.encoder.to(device)\n",
        "\n",
        "    self.decoder = decoder\n",
        "    # self.decoder.to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvqPja4xOwH7"
      },
      "source": [
        "## Обучение\n",
        "\n",
        "В качестве оптимизатора можете использовать SGD или Adam или в целом попробовать другие оптимизаторы, что предлагает pytorch.\n",
        "\n",
        "В качестве функции потерь воспользуйтесь MSE (MSELoss) или другой функцией, которая подходит для сравнения изображений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC-D2FjGOyMK"
      },
      "outputs": [],
      "source": [
        "log_dict = {\n",
        "    'training_loss_per_batch': [],\n",
        "    'validation_loss_per_batch': [],\n",
        "}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  print(f'Эпоха {epoch+1}/{epochs}')\n",
        "  train_losses = []\n",
        "\n",
        "  print('обучение...')\n",
        "  model.train()\n",
        "  for images in train_loader:\n",
        "\n",
        "    # Шаги для обучения:\n",
        "    # 1. загрузить изображения\n",
        "    # 2. добавить гауссовский шум шум (torch.normal() и clip() / clamp())\n",
        "    # 3. реконструировать изображение (прямой проход через энкодер и декодер)\n",
        "    # 4. рассчитать `loss`\n",
        "    # 5. выполнить `loss.backward ()` для вычисления градиентов функции потери относительно параметров модели\n",
        "    # 6. выполнить шаг оптимизации `optimizer.step ()`\n",
        "    # 7. занулить градиенты\n",
        "\n",
        "    #\n",
        "    # ваш код\n",
        "    #\n",
        "\n",
        "    log_dict['training_loss_per_batch'].append(loss.item())\n",
        "\n",
        "  # Валидация\n",
        "  print('валидация...')\n",
        "  model.eval()\n",
        "  for val_images in val_loader:\n",
        "    with torch.no_grad():\n",
        "      #\n",
        "      # ваш код\n",
        "      #\n",
        "\n",
        "      log_dict['validation_loss_per_batch'].append(val_loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ-5Lu-PSFZS"
      },
      "source": [
        "**Что делает clip() или clamp() и почему его требуется использовать после добавления шума?**\n",
        "\n",
        "Ваш ответ:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xowkG4-IEje"
      },
      "source": [
        "## Контроль результатов и экспериментов\n",
        "\n",
        "Вы всегда должны следить за тем как идет обучение и как меняются метрики в его процессе. В этой работе вы можете воспользоваться [TensorBoard](https://pytorch.org/docs/stable/tensorboard.html) или создать переменную со списком и в него складывать значения с каждых n итераций и с помощью matplotlib строить графики.\n",
        "\n",
        "Далее приведены части кода, которые позволят в Google Colab воспользоваться TensorBoard для PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjTP0E8xIE8A"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard  # Загружает один раз расширение для ноутбука. Эту команду можно перенести в самое начало.\n",
        "%tensorboard --logdir runs # Запускает сам tensorboard в выводе текущей ячейки. Лучше перенести в самый конец.\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter # Импорт модуля\n",
        "\n",
        "writer = SummaryWriter()  # создание экземпляра класса, который отвечает за ведение логов.\n",
        "\n",
        "for n_iter in range(100): # в цикле обучения вы используете метод add_scalar или другие для добавления записи в логи.\n",
        "    writer.add_scalar('Loss/train', np.random.random(), n_iter)  # пример вызова самого метода."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SVFv8hEUJ4n"
      },
      "source": [
        "**По графикам потерь и метрике сделайте вывод была ли модель обучена, недообучена или переобучена.**\n",
        "\n",
        "Ваш ответ:\n",
        "\n",
        "**Если модель недообучена или переобучена, то что могло послужить причинами этого?**\n",
        "\n",
        "Ваш ответ:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACjHbd2NKokt"
      },
      "source": [
        "## Результат работы модели\n",
        "\n",
        "Выведите итоговую метрику для тестовых изображений. И отобразите несколько примеров работы модели: исходное изображение и с убранным шумом.\n",
        "\n",
        "Пример для цветных изображений.\n",
        "\n",
        "```python\n",
        "test_images = test_images.to(device)\n",
        "with torch.no_grad():\n",
        "  reconstructed_imgs = network(test_images)\n",
        "reconstructed_imgs = reconstructed_imgs.cpu()\n",
        "test_images = test_images.cpu()\n",
        "imgs = torch.stack([test_images.view(-1, 3, 32, 32), reconstructed_imgs], dim=1).flatten(0,1)\n",
        "grid = make_grid(imgs, nrow=10, normalize=True, padding=1)\n",
        "grid = grid.permute(1, 2, 0)\n",
        "plt.figure(dpi=170)\n",
        "plt.title('Original/Reconstructed')\n",
        "plt.imshow(grid)\n",
        "log_dict['visualizations'].append(grid)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z185pkhyLHj4"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Ваш код\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM9Nf49VLJmT"
      },
      "source": [
        "## Контрольные вопросы\n",
        "\n",
        "**В чем особенность архитектуры автокодировщиков?**\n",
        "\n",
        "Ваш ответ:\n",
        "\n",
        "**Какие метрики можно использовать для оценки качества изображений?**\n",
        "\n",
        "Ваш ответ:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
